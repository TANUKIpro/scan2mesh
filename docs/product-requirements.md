# プロダクト要求定義書 (Product Requirements Document)

## プロダクト概要

### 名称
**scan2mesh** - RealSenseで撮るだけで、学習・シミュレーション用3Dアセットを生成するCLIツール

### プロダクトコンセプト
- **ワンショット3Dスキャン**: RealSenseカメラで撮影するだけで、シミュレーション・機械学習に使える3Dメッシュを自動生成
- **品質ゲート付きパイプライン**: 各ステージで品質を自動判定し、「使える/要注意/使えない」を明確化
- **再現可能なアセット生成**: 同じ入力・設定から同じ出力を得られる決定論的なパイプライン

### プロダクトビジョン
ロボット工学やシミュレーション開発において、実物体の3Dモデル作成は時間のかかる作業です。scan2meshは、RealSenseカメラ1台で撮影するだけで、シミュレーションや機械学習に必要な品質の3Dアセットを自動生成します。品質ゲートにより「このモデルは使える」「このモデルは危険」が明確になり、後工程での手戻りを最小化します。配布フォーマットを統一することで、Sim Pack（シミュレータ向けラッパー生成）やデータ合成パイプラインとのシームレスな連携を実現します。

### 目的
- RealSenseで撮影するだけで、一定品質の3Dアセットを生成できるようにする
- 品質ゲートにより、生成されたモデルの「使える/危険」を機械的に判定する
- 配布フォーマットを統一し、次工程（シミュレータ連携、データ合成）との接続を容易にする
- 再現可能なパイプラインにより、同じ入力から同じ出力を保証する

## ターゲットユーザー

### プライマリーペルソナ: 佐藤健太（32歳、ロボティクスエンジニア）
- **属性**: ロボカップやロボット競技会に参加するチームのエンジニア
- **技術スタック**: ROS2、Python、C++、シミュレータ（Gazebo、Isaac Sim等）
- **現在の課題**:
  - 競技で使う物体（ボール、ペットボトル等）の3Dモデルを手作業で作成している
  - CADで作ると実物と形状が微妙に異なり、シミュレーションと実機の乖離が発生
  - 市販の3Dスキャナは高価で、チームの予算では導入が難しい
- **期待する解決策**: RealSense（チームで既に所有）を使って、短時間で実物に近い3Dモデルを作成したい
- **1日の典型的なワークフロー**:
  1. 朝: シミュレータでアルゴリズムの開発・テスト
  2. 昼: 実機でのテスト、問題点の洗い出し
  3. 夕: シミュレータ環境の改善、翌日の準備

### セカンダリーペルソナ: 山田花子（28歳、MLエンジニア）
- **属性**: 物体認識モデルの学習データを作成するMLエンジニア
- **技術スタック**: PyTorch、BlenderProc、合成データ生成パイプライン
- **現在の課題**:
  - 学習データの多様性を確保するため、実物体の3Dモデルが大量に必要
  - 既存の3Dモデルデータセットでは、認識対象の物体がカバーされていない
  - 手作業でのモデリングは時間がかかりすぎる
- **期待する解決策**: 対象物体を素早くスキャンし、合成データ生成パイプラインに投入できる形式で出力したい

## 成功指標（KPI）

### プライマリーKPI
- **スキャン成功率**: 80%以上のスキャンがPASS判定（品質ゲート通過）
- **エンドツーエンド処理時間**: 撮影開始から配布可能なアセット生成まで15分以内（標準的な物体）
- **再現性**: 同一設定での再実行で、メッシュの頂点位置差が1mm以内

### セカンダリーKPI
- **ユーザーの習得時間**: 初回セットアップから最初の成功スキャンまで30分以内
- **手戻り率**: 品質ゲートでWARN/FAILとなった場合、1回の再撮影で解決できる割合70%以上

## 機能要件

### コア機能（MVP）

#### 1. プロジェクト初期化（Project Init）

**ユーザーストーリー**:
ロボティクスエンジニアとして、スキャン対象の物体情報を登録し、適切な設定でプロジェクトを開始したい

**受け入れ条件**:
- [ ] オブジェクト名とクラスIDを指定してプロジェクトを作成できる
- [ ] 出力プリセット（座標系、単位、テクスチャ解像度）を選択できる
- [ ] 既知の実寸（長辺mm、直径等）を任意で指定できる
- [ ] project.jsonに設定と履歴が保存される

**優先度**: P0（必須）

#### 2. 撮影計画生成（Capture Plan）

**ユーザーストーリー**:
ロボティクスエンジニアとして、短時間で十分なカバレッジを得るための撮影計画を自動生成してほしい

**受け入れ条件**:
- [ ] Quick（16-20視点）、Standard（24-36視点）、Hard（追加補完）のプリセットを選択できる
- [ ] capture_plan.jsonに推奨視点数、距離、角度、撮影順が出力される
- [ ] 計画に対して最低視点数が満たせる想定かの検証ができる

**優先度**: P0（必須）

#### 3. RGBD撮影（Capture）

**ユーザーストーリー**:
ロボティクスエンジニアとして、RealSenseからRGBDデータを取得し、リアルタイムで品質を監視しながら撮影したい

**受け入れ条件**:
- [ ] RealSenseストリーム（RGB、Depth、intrinsics、depth scale）を取得できる
- [ ] raw_frames/にRGB、Depth、timestamp、intrinsicsが保存される
- [ ] リアルタイムで品質指標（深度有効率、モーションブラー、カバレッジ、物体占有率）を表示できる
- [ ] 品質基準を満たさないフレームは自動除外される
- [ ] 計画視点の最低ラインを満たすまで「追加撮影」を促す警告が表示される

**優先度**: P0（必須）

#### 4. 前処理（Preprocess）

**ユーザーストーリー**:
ロボティクスエンジニアとして、撮影データから背景を除去し、復元に最適な状態に整えたい

**受け入れ条件**:
- [ ] Depthのフィルタリング（穴埋め、外れ値除去、軽度スムージング）が適用される
- [ ] RGB-Dアラインメントが実行される
- [ ] 背景除去方式を選択できる（A: 深度閾値+床平面推定、B: 手動バウンディング）
- [ ] masked_frames/に背景除去済みRGBDが保存される
- [ ] マスク品質が低い場合はCaptureへ戻すよう警告される

**優先度**: P0（必須）

#### 5. 3D復元（Reconstruct）

**ユーザーストーリー**:
ロボティクスエンジニアとして、前処理済みのRGBDデータから3Dメッシュを自動生成したい

**受け入れ条件**:
- [ ] フレーム間の姿勢推定（RGBD odometry）が実行される
- [ ] TSDFフュージョンで点群/ボリュームが統合される
- [ ] メッシュが抽出される
- [ ] テクスチャ（UV、アトラス）が生成される
- [ ] recon/にpointcloud.ply、mesh_raw.glb、recon_report.jsonが出力される
- [ ] 追跡破綻（大ジャンプ、残差急増）を検出し、警告または区間破棄ができる
- [ ] メッシュの欠損が大きい場合はCaptureへ戻すよう警告される

**優先度**: P0（必須）

#### 6. アセット最適化（Asset Optimize）

**ユーザーストーリー**:
ロボティクスエンジニアとして、生成されたメッシュをシミュレーション・学習に適した形式に最適化したい

**受け入れ条件**:
- [ ] スケールが確定される（既知実寸またはRealSenseスケール、不確かさをメタデータに記録）
- [ ] 軸/原点が正規化される（Z-up、原点=底面中心、+Y前方）
- [ ] メッシュ修正（法線修正、非多様体/穴の軽微修正、孤立片除去）が適用される
- [ ] LOD生成（LOD0: ~100k tris、LOD1: ~30k、LOD2: ~10k）が実行される
- [ ] Collision mesh（Convex hull、オプションで凸分解）が生成される
- [ ] テクスチャ調整（2k上限、圧縮）が適用される
- [ ] asset/にvisual_lod0-2.glb、collision.obj、preview.png、asset_metrics.jsonが出力される

**優先度**: P0（必須）

#### 7. パッケージング（Package）

**ユーザーストーリー**:
ロボティクスエンジニアとして、生成されたアセットを配布可能な形式でパッケージングしたい

**受け入れ条件**:
- [ ] 規定のフォルダ構造でアセットバンドルが生成される
- [ ] manifest.jsonに全メタデータ（オブジェクト情報、座標系、スケール、品質ステータス、来歴）が記録される
- [ ] 品質ステータス（PASS/WARN/FAIL）と理由が記録される
- [ ] ZIPまたはフォルダ形式で出力できる

**優先度**: P0（必須）

#### 8. 品質レポート（Report）

**ユーザーストーリー**:
ロボティクスエンジニアとして、生成されたアセットの品質と次に取るべきアクションを確認したい

**受け入れ条件**:
- [ ] キャプチャ品質（フレーム数、深度有効率、ブラースコア、カバレッジ）が表示される
- [ ] 復元品質（追跡成功率、アライメントRMSE、ドリフト指標）が表示される
- [ ] アセット品質（三角形数、穴面積率、非多様体エッジ数、テクスチャ解像度、AABB、衝突複雑度）が表示される
- [ ] 総合判定（PASS/WARN/FAIL）と理由、次アクションの提案が表示される

**優先度**: P0（必須）

### CLIインターフェース

```bash
# プロジェクト初期化
scan2mesh init --name robocup_ball --class-id 0 [--dimension 220]

# 撮影計画の生成
scan2mesh plan --preset quick|standard|hard

# 撮影の実行
scan2mesh capture [--plan quick]

# 前処理
scan2mesh preprocess [--background-removal depth|manual]

# 3D復元
scan2mesh reconstruct

# アセット最適化
scan2mesh optimize --preset canonical

# パッケージング
scan2mesh package --out bundle.zip

# 品質レポート
scan2mesh report
```

### 将来的な機能（Post-MVP）

#### ターンテーブル連携によるSLAMレス撮影

サーボモータ制御のターンテーブルと連携し、オブジェクトの回転角度をリアルタイムで取得する。これにより、SLAM（姿勢推定）が不要となり、より高精度で安定した3D復元が可能になる。

**期待される効果**:
- 姿勢推定の誤差・ドリフトが排除される
- 復元の安定性が大幅に向上
- 処理時間の短縮（odometry計算が不要）

**優先度**: P1（重要）

#### カメラIMU連携

カメラに小型IMUを搭載し、カメラの向き（姿勢）を正確に取得する。ターンテーブル連携と組み合わせることで、オブジェクトとカメラ双方の姿勢が既知となり、完全にSLAMフリーな撮影が実現できる。

**期待される効果**:
- カメラの手ブレ・傾きを正確に補正
- ターンテーブル＋IMUで完全な姿勢情報を取得
- より高精度なRGB-Dアラインメント

**優先度**: P1（重要）

#### 2Dセグメンテーションによる背景除去

Segment Anything等のモデルを使用した高精度な背景除去

**優先度**: P2（できれば）

#### 複数オブジェクト同時スキャン

一度の撮影で複数の物体をスキャンし、個別のアセットとして分離

**優先度**: P2（できれば）

#### Webベースのプレビューア

生成されたアセットをブラウザで3D表示・確認できるビューア

**優先度**: P2（できれば）

## 非機能要件

### パフォーマンス
- **撮影フレームレート**: 15fps以上でRGBDストリームを取得できる
- **前処理時間**: 100フレームを60秒以内で処理できる
- **復元時間**: 100フレームから5分以内でメッシュを生成できる
- **最適化時間**: 100k三角形のメッシュを2分以内で最適化できる

### ユーザビリティ
- **セットアップ**: READMEを読んで15分以内にセットアップが完了できる
- **習得**: 初回ユーザーが30分以内に最初の成功スキャンを完了できる
- **エラーメッセージ**: すべてのエラーに対して、原因と解決策が明示される
- **進捗表示**: 長時間処理にはプログレスバーと推定残り時間が表示される

### 信頼性
- **データ損失ゼロ**: 処理中断時も撮影データは保持される
- **再開可能**: 中断した処理を途中から再開できる
- **エラー復旧**: エラー発生時に明確なリカバリーパスが提示される

### 再現性
- **決定論的出力**: 同一入力・設定で実行した場合、同一の出力が得られる
- **設定の記録**: すべての出力にconfig hashが含まれる
- **バージョン管理**: ツールバージョンが出力メタデータに記録される

### セキュリティ・プライバシー
- **ローカル完結（必須）**: すべての処理はローカルマシン上で完結する。外部サーバーへのデータ送信は一切行わない。これは将来の拡張においても変更不可の原則とする
- **オフライン動作**: インターネット接続なしで全機能が動作する
- **入力検証**: 外部からの入力（ファイルパス等）は適切にサニタイズされる

### 互換性
- **対応OS**: Ubuntu 22.04 LTS、Ubuntu 24.04 LTS
- **対応カメラ**: Intel RealSense D400シリーズ（D415、D435、D455）
- **Python**: 3.10以上

### 実行環境
- **Docker必須**: すべての機能はDockerコンテナ内で動作する。これにより異なるデバイス間で環境を共有できる
- **コンテナランタイム**: Docker 24.0以上、Docker Compose 2.20以上
- **GPU対応**: NVIDIA GPU + CUDA 12.x + NVIDIA Container Toolkit 1.14以上
- **USBパススルー**: RealSenseカメラへのアクセスはUSBデバイスパススルーで実現

## スコープ外

明示的にスコープ外とする項目:

- **シミュレータ固有フォーマット生成**: URDF、SDF、USDのラッパ生成は別ツール（Sim Pack）の責務
- **反射・透明・黒物体の高精度スキャン**: これらは品質ゲートでWARN/FAILとし、別手段への誘導のみ行う
- **リアルタイム3D復元**: 撮影後のバッチ処理を前提とする
- **クラウド処理**: すべてローカルで完結する
- **GUI**: CLIファーストとし、GUIは将来の拡張として検討
